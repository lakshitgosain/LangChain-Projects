{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lakshitgosain/LangChain-Projects/blob/main/Langchain_Pdf_query.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ubRRNtcQ7MS8"
      },
      "outputs": [],
      "source": [
        "!pip install -q cassio datasets langchain openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mp8Uv9K37Qp7",
        "outputId": "9e4da058-58bd-430f-a36c-edea4cec2170"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: PyPdf2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install PyPdf2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OYfFIxKy7jb0"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores.cassandra import Cassandra\n",
        "from langchain.indexes.vectorstore import VectorStoreIndexWrapper\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "#Cassio powers the AstraDB Integration in LangChain\n",
        "import cassio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uyni6iae91Nl"
      },
      "outputs": [],
      "source": [
        "from PyPDF2 import PdfReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCHrAWMd-LnG"
      },
      "outputs": [],
      "source": [
        "ASTRA_DB_APPLICATION_TOKEN=\"AstraCS:BXvgSTZrfYvIOBaqLFwwnuid:961307bd7827efc6236684fa1f5c49de652f8f39582686c5093d17bc390ff600\"\n",
        "ASTRA_DB_ID=\"f4d418f1-9aa2-480d-b739-80de6efacec4\"\n",
        "\n",
        "OPENAI_API_KEY=\"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2v6vDUHAFaV"
      },
      "outputs": [],
      "source": [
        "pdfreader=PdfReader(\"Lakshit_Gosain_AIML_MLOPS_Cloud_CV.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ljWBnUaAmhT"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import Concatenate\n",
        "raw_text=\"\"\n",
        "for i, page in enumerate(pdfreader.pages):\n",
        "\n",
        "  content=page.extract_text()\n",
        "  if content:\n",
        "    raw_text+=content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "bS7TM0qOA_jL",
        "outputId": "07295144-74ca-4c56-fc6d-3ecec5f56bf0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"+91 9811894268\\nlakshit.gosain@gmail.com\\nNew Delhi, IndiaC O N T A C T P R O F I L E\\nS K I L L S\\nW O R K  E X P E R I E N C E\\nData Science/Machine Learning\\nDeep LearningTata Consultancy Services(IT Analyst - Data Scientist)\\nGE having various research verticals had a repository for all the Research based\\ndocuments which were not being marked for various research type/category,\\nmaking it difficult for global teams to find out relevant documents of use.\\nEstablished ML pipelines using NLP techniques and Machine Learning\\nto Tag research Documents among more than 400 tags and also\\nidentify which organisations were a part of the Research.\\nA total of 62000 documents were tagged on Day 0, after which the tagging\\nprocess runs as a batch job.\\nTech Stack - Python , NLP, Numpy , Pandas, sklearn, spacy, nltk, Tensorflow,\\nAWS Textract, AWS Glue, AWS Lambda, S3, Sagemaker.\\nAgile - JIRA\\nBusiness Impact -  7600 hrs Annual Productivity boost.Nov 2021-PresentI have 5+ years of work experience in Data Science with a proven\\nability and history of developing full-stack data science projects. I\\nhave worked extensively in developing Robust and Scalable\\nApplications and micro-services that creating immense business\\nimpacts.L A K S H I T  G O S A I N\\nDATA SCIENTIST\\nNatural Language ProcessingPython\\nTensorflowAWS CloudSQL \\nVector DB - Pinecone/OpensearchDecarbonization / Avery ProjectGeneral Electric (GE Vernova)\\nER Case Similarity Project\\nEngineering Requests(ER) were being raised in the DataNow application since a\\nlong time to resolve issues and concerns related to GE’s Core Businesses\\noperations/technologies like Windmills, turbines, spare parts etc, providing a\\nhuge reserve of data to be utilised.\\nThe historical data was made use of to develop a Similar ER Case recommender\\nbased on the input of description of the challenge/ticket being searched for.\\nTech Stack -  Python, NLP, pandas, sentence-transformers(HuggingFace -\\nMPNet base V2), Vector Database (Opensearch) Sagemaker (Pipelines,\\nEndpoint, Notebook, Studio), Lambda Functions, S3 , AWS Step Functions.\\nAgile - Rally Board\\nBusiness Impact -   Estimated 15000 hrs Annual Productivity\\nEstimated Logistics Cost (ELC) Project\\nGE Ships around 90000 shipments per year. Getting the estimates ahead of time\\ncan take up to 4 weeks due to carrier delays.\\nA solution was developed which would give the logistics team a clear vision of\\nan estimated shipment cost and deciding on the cheapest route for the\\nshipment\\nTech stack used - Python , sklearn, pandas, numpy, AWS Eventbridge\\nSagemaker(Notebook,Endpoint), , AWS GLUE, SQL, S3, AWS Step Function\\nAglie - Rally Board\\nBusiness Impact -  $75000/year of savingsMLOPs\\nTransformers\\nPyspark\\nDocker\\nC E R T I F I C A T I O N STableauGenerative AI, LLM & LangChain\\nAWS Certified Cloud Practitioner\\nAWS Certified Machine Learning –\\nSpecialty\\nLangChain - Develop LLM powered\\nApplications\\nDeep Learning A-Z\\nHands-on Machine Learning\\nL A N G U A G E S\\nEnglish\\nHindi\\nPunjabiSalesforce123-456-7890\\nhello@reallygreatsite.com\\nwww.reallygreatsite.com\\n123 Anywhere St., Any CityC O N T A C T\\nE X P E R T I S E\\nR E F E R E N C E SLorem ipsum dolor sit amet,\\nconsectetur adipiscing elit. Aliquam\\nsagittis pretium nisl, nec commodo\\nest. \\nFusce laoreet consequat sapien, eu\\nfermentum ex pulvinar eget.\\nPraesent hendrerit nulla in varius\\npharetra. Fusce facilisis venenatis\\nlacus in lobortis. Fusce vulputate\\niaculis mauris.  \\nNunc risus arcu, tempor vel\\ndignissim porta, vulputate id quam.\\nVestibulum pellentesque augue in\\nlobortis ullamcorper.  \\nIn eleifend nisl faucibus molestie\\nporttitor.  \\n risus arcu, tempor vel dignissim\\nporta, vulputate id quam.\\nVestibulum pellentesque augue in\\nlobortis ullamcorper.  \\nIn eleifend nisl faucibus molestie.\\nReference Name\\n123-456-7890\\nhello@reallygreatsite.com\\nReference Name\\n123-456-7890\\nhello@reallygreatsite.comInbound Logistics and Shipments between GE Suppliers, plants and warehouses\\nare planned according to material schedule requirements. However, there was\\nno automated technique to allow for shipment consolidation. The\\nconsolidations were done manually. This created an opportunity cost in\\ndevelopment of the project\\nConsolidated the results in Tableau Dashboard and also provided the routers\\nwith the prediction of ready to ship date for each consignment.\\nTech Stack -  Python, sklearn, pandas, numpy, Sagemaker, AWS GLUE,\\nSQL,AWS EventBridge , Tableau, AWS Step Functions\\nAgile - Rally Board\\nBusiness Impact - 5000 hr Annual Productivity boostNetwork Optimization and Consolidation (NOC)\\nCS Business is unable to layout a comprehensive view of what it's obligations\\nand entitlements are as defined in the Terms and Conditions in the signed CSAs,\\ndue to which a lot of scope creep and a potential leakage of billing was seen\\nduring the execution.\\nA solution was developed to perform contextual search using NLP Techniques\\nto search on contracts and provide answers to coverage related questions  \\nTech stack used -  Python, Parsr(Open source tool for text extraction), NLP,\\nHuggingFace Sentence-transformer(paraphrase-miniLM-l6), AWS GLUE, AWS\\nLambda, S3,  \\nAgile - Rally Board\\nBusiness Impact - 1000 hr Annual Productivity BoostTerms and Conditions (T&Cs)\\nContributed towards development of a platform within AWS Cloud, to deploy\\nsolutions within a predefined and specified and approved architecture (by\\nSecurity and various other teams).\\nDeveloped POC for model Retraining Mechanisms and model monitoring\\ntechniques\\nMLOPs concepts were built as a part of the platform and can be used by several\\nprojects\\nDeveloped translation services which were using AWS Translate along with\\nsome customised functionalities.These translation services were used across\\nvarious formats like .pdf, .ppt, excel, image, text etc and were consumed by\\nGlobal GE Teams to process highly confidential data.\\nDecarb, T&Cs, ER Case similarity were later deployed within the same\\nArchitecture.Platform Capability Build /AIML Management Suite\\nProtiviti Consulting Pvt. Ltd. (Senior Technical\\nEngineer )Jan ‘21-Nov ’21\\nBuilt Chatbot System using Machine Learning and Deep Learning Techniques to\\nhelp answer queries of customers\\nProtiviti Consulting Pvt. Ltd. (Technical Engineer ) Jan ‘18 - Jan ‘21\\nAnalysed Customer Satisfaction Survey using Natural Language Processing/\\nMachine Learning to help identify improvement areas.  \\nWorked in deployment and maintenance of Applications(M.L/D.L.) to AWS\\nCloud.  \\nAutomated Repetitive and Tedious Tasks performed by Several Teams using\\nPython Programming  \\nBuilt Machine Learning & Deep Learning Models using Internally Existing Data to\\nhelp make better decisions.  \\nSuccessfully worked with the Product Management Team to use Client Data and\\nbuild machine Learning Models For SOX Compliance Domain.  E D U C A T I O N\\nBachelors of\\nTechnology(B.Tech- CSE)\\nNorthCap University (Formerly ITM\\nUniversity)                            \\nXII: Non Medical (Computer\\nScience)\\nSt. Marks Sen. Sec Public School \\nYear - 2013-2014Percentage - 82%CGPA - 7.23\\nYear - 2014-2018\\nP R O J E C T S\\nProjects can be referred in the\\nGitHub in Multiple\\nRepositories. Have tried to\\nwork and improve on each\\nskill and continuously up skill.\\nA W A R D S  A N D\\nA P P R E C I A T I O N S\\nOn the Spot Award - May ‘23\\nCIO Team Appreciation - Apr\\n‘23\\nStar of the Month - March ‘23\\nBest New Joiner - Aug ‘22\\n(S)miles Award - May ‘22\\n(S)miles Award - March ‘22\\nQuarterly Best Performer -\\nJan ‘ 21\\nStar of the Month - Aug ‘19\\nBest New Joiner - Jan ‘18\\nMultiple Appreciations from\\nClient including a few coming\\ndirectly from Client’s Director\\nof Engineering Team\""
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9MwhiUABBl2",
        "outputId": "9ad15e86-b61b-4a82-fff0-8c6bb4f3f719"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for f4d418f1-9aa2-480d-b739-80de6efacec4-us-east1.db.astra.datastax.com:29042:ceba643e-b237-470a-b0be-b86329b59e66. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for f4d418f1-9aa2-480d-b739-80de6efacec4-us-east1.db.astra.datastax.com:29042:ceba643e-b237-470a-b0be-b86329b59e66. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(132999222307584) f4d418f1-9aa2-480d-b739-80de6efacec4-us-east1.db.astra.datastax.com:29042:ceba643e-b237-470a-b0be-b86329b59e66> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for f4d418f1-9aa2-480d-b739-80de6efacec4-us-east1.db.astra.datastax.com:29042:ceba643e-b237-470a-b0be-b86329b59e66. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        }
      ],
      "source": [
        "cassio.init(token=ASTRA_DB_APPLICATION_TOKEN, database_id=ASTRA_DB_ID)#Initialize the DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP6ApZJMBN7D",
        "outputId": "70f2ef02-7a8b-4c5a-8531-924ddfceb424"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n",
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "llm=OpenAI(openai_api_key=OPENAI_API_KEY)\n",
        "embedding=OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHl723s_BbiZ"
      },
      "outputs": [],
      "source": [
        "#Create Langchain Vectorstore backed by Astra DB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFGsal-1Bgfh"
      },
      "outputs": [],
      "source": [
        "astra_vector_store=Cassandra(\n",
        "    embedding=embedding,\n",
        "    table_name=\"QA_demo\",\n",
        "    session=None,\n",
        "    keyspace=None\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3jcG1UaBuK_"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import CharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U4yq-hlBsaM"
      },
      "outputs": [],
      "source": [
        "text_splitter=CharacterTextSplitter(\n",
        "    separator=\"\\n\",\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        "    length_function=len,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3viwl0XvCI7D"
      },
      "outputs": [],
      "source": [
        "texts=text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfyNeH64CKtn",
        "outputId": "783a02f4-d8db-4a84-f3c4-be9821dbfb65"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "968"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(texts[7])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_vNzsRrCd5U"
      },
      "outputs": [],
      "source": [
        "astra_vector_store.add_texts(texts[:50])\n",
        "\n",
        "astra_vector_index=VectorStoreIndexWrapper(vectorstore=astra_vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXU_3_mEDSmt",
        "outputId": "82b3dc5e-2931-406e-e750-efff3792944c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Question \"what is the contact number\"\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n",
            "WARNING:cassandra.protocol:Server warning: Top-K queries can only be run with consistency level ONE / LOCAL_ONE / NODE_LOCAL. Consistency level LOCAL_QUORUM was requested. Downgrading the consistency level to LOCAL_ONE.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8875930567521573 R E F E R E N C E SLorem ipsum dolor sit amet,\n",
            "consectetur adipiscing elit. Aliquam\n",
            "sagittis pretium nisl, nec commodo\n",
            "est. \n",
            "Fusce laoreet consequat sapien, eu\n",
            "fermentum ex pulvinar eget.\n",
            "Praesent hendrerit nulla in varius\n",
            "pharetra. Fusce facilisis venenatis\n",
            "lacus in lobortis. Fusce vulputate\n",
            "iaculis mauris.  \n",
            "Nunc risus arcu, tempor vel\n",
            "dignissim porta, vulputate id quam.\n",
            "Vestibulum pellentesque augue in\n",
            "lobortis ullamcorper.  \n",
            "In eleifend nisl faucibus molestie\n",
            "porttitor.  \n",
            " risus arcu, tempor vel dignissim\n",
            "porta, vulputate id quam.\n",
            "Vestibulum pellentesque augue in\n",
            "lobortis ullamcorper.  \n",
            "In eleifend nisl faucibus molestie.\n",
            "Reference Name\n",
            "123-456-7890\n",
            "hello@reallygreatsite.com\n",
            "Reference Name\n",
            "123-456-7890\n",
            "hello@reallygreatsite.comInbound Logistics and Shipments between GE Suppliers, plants and warehouses\n",
            "are planned according to material schedule requirements. However, there was\n",
            "no automated technique to allow for shipment consolidation. The\n",
            "0.8875930567521573 R E F E R E N C E SLorem ipsum dolor sit amet,\n",
            "consectetur adipiscing elit. Aliquam\n",
            "sagittis pretium nisl, nec commodo\n",
            "est. \n",
            "Fusce laoreet consequat sapien, eu\n",
            "fermentum ex pulvinar eget.\n",
            "Praesent hendrerit nulla in varius\n",
            "pharetra. Fusce facilisis venenatis\n",
            "lacus in lobortis. Fusce vulputate\n",
            "iaculis mauris.  \n",
            "Nunc risus arcu, tempor vel\n",
            "dignissim porta, vulputate id quam.\n",
            "Vestibulum pellentesque augue in\n",
            "lobortis ullamcorper.  \n",
            "In eleifend nisl faucibus molestie\n",
            "porttitor.  \n",
            " risus arcu, tempor vel dignissim\n",
            "porta, vulputate id quam.\n",
            "Vestibulum pellentesque augue in\n",
            "lobortis ullamcorper.  \n",
            "In eleifend nisl faucibus molestie.\n",
            "Reference Name\n",
            "123-456-7890\n",
            "hello@reallygreatsite.com\n",
            "Reference Name\n",
            "123-456-7890\n",
            "hello@reallygreatsite.comInbound Logistics and Shipments between GE Suppliers, plants and warehouses\n",
            "are planned according to material schedule requirements. However, there was\n",
            "no automated technique to allow for shipment consolidation. The\n",
            "0.886601654061715 +91 9811894268\n",
            "lakshit.gosain@gmail.com\n",
            "New Delhi, IndiaC O N T A C T P R O F I L E\n",
            "S K I L L S\n",
            "W O R K  E X P E R I E N C E\n",
            "Data Science/Machine Learning\n",
            "Deep LearningTata Consultancy Services(IT Analyst - Data Scientist)\n",
            "GE having various research verticals had a repository for all the Research based\n",
            "documents which were not being marked for various research type/category,\n",
            "making it difficult for global teams to find out relevant documents of use.\n",
            "Established ML pipelines using NLP techniques and Machine Learning\n",
            "to Tag research Documents among more than 400 tags and also\n",
            "identify which organisations were a part of the Research.\n",
            "A total of 62000 documents were tagged on Day 0, after which the tagging\n",
            "process runs as a batch job.\n",
            "Tech Stack - Python , NLP, Numpy , Pandas, sklearn, spacy, nltk, Tensorflow,\n",
            "AWS Textract, AWS Glue, AWS Lambda, S3, Sagemaker.\n",
            "Agile - JIRA\n",
            "0.886601654061715 +91 9811894268\n",
            "lakshit.gosain@gmail.com\n",
            "New Delhi, IndiaC O N T A C T P R O F I L E\n",
            "S K I L L S\n",
            "W O R K  E X P E R I E N C E\n",
            "Data Science/Machine Learning\n",
            "Deep LearningTata Consultancy Services(IT Analyst - Data Scientist)\n",
            "GE having various research verticals had a repository for all the Research based\n",
            "documents which were not being marked for various research type/category,\n",
            "making it difficult for global teams to find out relevant documents of use.\n",
            "Established ML pipelines using NLP techniques and Machine Learning\n",
            "to Tag research Documents among more than 400 tags and also\n",
            "identify which organisations were a part of the Research.\n",
            "A total of 62000 documents were tagged on Day 0, after which the tagging\n",
            "process runs as a batch job.\n",
            "Tech Stack - Python , NLP, Numpy , Pandas, sklearn, spacy, nltk, Tensorflow,\n",
            "AWS Textract, AWS Glue, AWS Lambda, S3, Sagemaker.\n",
            "Agile - JIRA\n"
          ]
        }
      ],
      "source": [
        "first_question=True\n",
        "while True:\n",
        "  if first_question:\n",
        "    query_text=input(\"Enter your question(or type exit to quit)\").strip()\n",
        "  else:\n",
        "    query_text=input(\"Enter your next Question\").strip()\n",
        "\n",
        "  if query_text.lower()==\"quit\":\n",
        "    break\n",
        "  if query_text==\"\":\n",
        "    continue\n",
        "\n",
        "  first_question=False\n",
        "  print(\"\\nQuestion \\\"%s\\\"\" %query_text)\n",
        "  answer=astra_vector_index.query(query_text, llm=llm).strip()\n",
        "\n",
        "  for doc,score in astra_vector_store.similarity_search_with_score(query_text, k=4):\n",
        "    print(score, doc.page_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-ODGyvnFSRL"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkW0yKSfQ3Ts",
        "outputId": "2c6bf14c-fbdd-497d-9102-f3bb4966bf6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.10/dist-packages (4.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEePl7N9QPme"
      },
      "outputs": [],
      "source": [
        "data_doc=PyPDFLoader(\"Lakshit_Gosain_AIML_MLOPS_Cloud_CV.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVWtIn3oQoD4"
      },
      "outputs": [],
      "source": [
        "raw_text_loaded=data_doc.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAE-wjWhRBNK",
        "outputId": "fa2c3d14-8457-4df9-b5ff-c14fd0a152cd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(page_content='+91 9811894268\\nlakshit.gosain@gmail.com\\nNew Delhi, IndiaC O N T A C T P R O F I L E\\nS K I L L S\\nW O R K  E X P E R I E N C E\\nData Science/Machine Learning\\nDeep LearningTata Consultancy Services(IT Analyst - Data Scientist)\\nGE having various research verticals had a repository for all the Research based\\ndocuments which were not being marked for various research type/category,\\nmaking it difficult for global teams to find out relevant documents of use.\\nEstablished ML pipelines using NLP techniques and Machine Learning\\nto Tag research Documents among more than 400 tags and also\\nidentify which organisations were a part of the Research.\\nA total of 62000 documents were tagged on Day 0, after which the tagging\\nprocess runs as a batch job.\\nTech Stack - Python , NLP, Numpy , Pandas, sklearn, spacy, nltk, Tensorflow,\\nAWS Textract, AWS Glue, AWS Lambda, S3, Sagemaker.\\nAgile - JIRA\\nBusiness Impact -  7600 hrs Annual Productivity boost.Nov 2021-PresentI have 5+ years of work experience in Data Science with a proven\\nability and history of developing full-stack data science projects. I\\nhave worked extensively in developing Robust and Scalable\\nApplications and micro-services that creating immense business\\nimpacts.L A K S H I T  G O S A I N\\nDATA SCIENTIST\\nNatural Language ProcessingPython\\nTensorflowAWS CloudSQL \\nVector DB - Pinecone/OpensearchDecarbonization / Avery ProjectGeneral Electric (GE Vernova)\\nER Case Similarity Project\\nEngineering Requests(ER) were being raised in the DataNow application since a\\nlong time to resolve issues and concerns related to GE’s Core Businesses\\noperations/technologies like Windmills, turbines, spare parts etc, providing a\\nhuge reserve of data to be utilised.\\nThe historical data was made use of to develop a Similar ER Case recommender\\nbased on the input of description of the challenge/ticket being searched for.\\nTech Stack -  Python, NLP, pandas, sentence-transformers(HuggingFace -\\nMPNet base V2), Vector Database (Opensearch) Sagemaker (Pipelines,\\nEndpoint, Notebook, Studio), Lambda Functions, S3 , AWS Step Functions.\\nAgile - Rally Board\\nBusiness Impact -   Estimated 15000 hrs Annual Productivity\\nEstimated Logistics Cost (ELC) Project\\nGE Ships around 90000 shipments per year. Getting the estimates ahead of time\\ncan take up to 4 weeks due to carrier delays.\\nA solution was developed which would give the logistics team a clear vision of\\nan estimated shipment cost and deciding on the cheapest route for the\\nshipment\\nTech stack used - Python , sklearn, pandas, numpy, AWS Eventbridge\\nSagemaker(Notebook,Endpoint), , AWS GLUE, SQL, S3, AWS Step Function\\nAglie - Rally Board\\nBusiness Impact -  $75000/year of savingsMLOPs\\nTransformers\\nPyspark\\nDocker\\nC E R T I F I C A T I O N STableauGenerative AI, LLM & LangChain\\nAWS Certified Cloud Practitioner\\nAWS Certified Machine Learning –\\nSpecialty\\nLangChain - Develop LLM powered\\nApplications\\nDeep Learning A-Z\\nHands-on Machine Learning\\nL A N G U A G E S\\nEnglish\\nHindi\\nPunjabiSalesforce', metadata={'source': 'Lakshit_Gosain_AIML_MLOPS_Cloud_CV.pdf', 'page': 0}),\n",
              " Document(page_content=\"123-456-7890\\nhello@reallygreatsite.com\\nwww.reallygreatsite.com\\n123 Anywhere St., Any CityC O N T A C T\\nE X P E R T I S E\\nR E F E R E N C E SLorem ipsum dolor sit amet,\\nconsectetur adipiscing elit. Aliquam\\nsagittis pretium nisl, nec commodo\\nest. \\nFusce laoreet consequat sapien, eu\\nfermentum ex pulvinar eget.\\nPraesent hendrerit nulla in varius\\npharetra. Fusce facilisis venenatis\\nlacus in lobortis. Fusce vulputate\\niaculis mauris.  \\nNunc risus arcu, tempor vel\\ndignissim porta, vulputate id quam.\\nVestibulum pellentesque augue in\\nlobortis ullamcorper.  \\nIn eleifend nisl faucibus molestie\\nporttitor.  \\n risus arcu, tempor vel dignissim\\nporta, vulputate id quam.\\nVestibulum pellentesque augue in\\nlobortis ullamcorper.  \\nIn eleifend nisl faucibus molestie.\\nReference Name\\n123-456-7890\\nhello@reallygreatsite.com\\nReference Name\\n123-456-7890\\nhello@reallygreatsite.comInbound Logistics and Shipments between GE Suppliers, plants and warehouses\\nare planned according to material schedule requirements. However, there was\\nno automated technique to allow for shipment consolidation. The\\nconsolidations were done manually. This created an opportunity cost in\\ndevelopment of the project\\nConsolidated the results in Tableau Dashboard and also provided the routers\\nwith the prediction of ready to ship date for each consignment.\\nTech Stack -  Python, sklearn, pandas, numpy, Sagemaker, AWS GLUE,\\nSQL,AWS EventBridge , Tableau, AWS Step Functions\\nAgile - Rally Board\\nBusiness Impact - 5000 hr Annual Productivity boostNetwork Optimization and Consolidation (NOC)\\nCS Business is unable to layout a comprehensive view of what it's obligations\\nand entitlements are as defined in the Terms and Conditions in the signed CSAs,\\ndue to which a lot of scope creep and a potential leakage of billing was seen\\nduring the execution.\\nA solution was developed to perform contextual search using NLP Techniques\\nto search on contracts and provide answers to coverage related questions  \\nTech stack used -  Python, Parsr(Open source tool for text extraction), NLP,\\nHuggingFace Sentence-transformer(paraphrase-miniLM-l6), AWS GLUE, AWS\\nLambda, S3,  \\nAgile - Rally Board\\nBusiness Impact - 1000 hr Annual Productivity BoostTerms and Conditions (T&Cs)\\nContributed towards development of a platform within AWS Cloud, to deploy\\nsolutions within a predefined and specified and approved architecture (by\\nSecurity and various other teams).\\nDeveloped POC for model Retraining Mechanisms and model monitoring\\ntechniques\\nMLOPs concepts were built as a part of the platform and can be used by several\\nprojects\\nDeveloped translation services which were using AWS Translate along with\\nsome customised functionalities.These translation services were used across\\nvarious formats like .pdf, .ppt, excel, image, text etc and were consumed by\\nGlobal GE Teams to process highly confidential data.\\nDecarb, T&Cs, ER Case similarity were later deployed within the same\\nArchitecture.Platform Capability Build /AIML Management Suite\\nProtiviti Consulting Pvt. Ltd. (Senior Technical\\nEngineer )Jan ‘21-Nov ’21\\nBuilt Chatbot System using Machine Learning and Deep Learning Techniques to\\nhelp answer queries of customers\\nProtiviti Consulting Pvt. Ltd. (Technical Engineer ) Jan ‘18 - Jan ‘21\\nAnalysed Customer Satisfaction Survey using Natural Language Processing/\\nMachine Learning to help identify improvement areas.  \\nWorked in deployment and maintenance of Applications(M.L/D.L.) to AWS\\nCloud.  \\nAutomated Repetitive and Tedious Tasks performed by Several Teams using\\nPython Programming  \\nBuilt Machine Learning & Deep Learning Models using Internally Existing Data to\\nhelp make better decisions.  \\nSuccessfully worked with the Product Management Team to use Client Data and\\nbuild machine Learning Models For SOX Compliance Domain.  E D U C A T I O N\\nBachelors of\\nTechnology(B.Tech- CSE)\\nNorthCap University (Formerly ITM\\nUniversity)                            \\nXII: Non Medical (Computer\\nScience)\\nSt. Marks Sen. Sec Public School \\nYear - 2013-2014Percentage - 82%CGPA - 7.23\\nYear - 2014-2018\\nP R O J E C T S\\nProjects can be referred in the\\nGitHub in Multiple\\nRepositories. Have tried to\\nwork and improve on each\\nskill and continuously up skill.\\nA W A R D S  A N D\\nA P P R E C I A T I O N S\\nOn the Spot Award - May ‘23\\nCIO Team Appreciation - Apr\\n‘23\\nStar of the Month - March ‘23\\nBest New Joiner - Aug ‘22\\n(S)miles Award - May ‘22\\n(S)miles Award - March ‘22\\nQuarterly Best Performer -\\nJan ‘ 21\\nStar of the Month - Aug ‘19\\nBest New Joiner - Jan ‘18\\nMultiple Appreciations from\\nClient including a few coming\\ndirectly from Client’s Director\\nof Engineering Team\", metadata={'source': 'Lakshit_Gosain_AIML_MLOPS_Cloud_CV.pdf', 'page': 1})]"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "raw_text_loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzy4bKLKRkAn"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import MarkdownHeaderTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6bAQ7LLRTzA"
      },
      "outputs": [],
      "source": [
        "text_splitter=MarkdownHeaderTextSplitter(headers_to_split_on=[\"Work Experience\",\"Profile\", \"Skills\",\"Contact\",\"Certifications\",\"Languages\",\"Education\",\"Awards and Appreciations\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "akGPF6-JR3Ic",
        "outputId": "dfd690d4-ce97-4875-cb74-d9a02f961500"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "too many values to unpack (expected 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-da9d8eaebd47>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_splitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain/text_splitter.py\u001b[0m in \u001b[0;36msplit_text\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;31m# Check each line against each of the header types (e.g., #, ##)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders_to_split_on\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                 \u001b[0;31m# Check if line starts with a header that we intend to split on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                 if stripped_line.startswith(sep) and (\n",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ],
      "source": [
        "texts=text_splitter.split_text(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIZrteeRSps9"
      },
      "outputs": [],
      "source": [
        "len(raw_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jOpWOMq3Tj7T"
      },
      "outputs": [],
      "source": [
        "!pip install pdf-to-markdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbLL8CGkTkZG"
      },
      "outputs": [],
      "source": [
        "llm.query(\"Can you convert this document to markdown?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKevaCFsUfxz"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ze3r9tcdUqzP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMOnXyEpO0iT6+A3cq/DgZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}